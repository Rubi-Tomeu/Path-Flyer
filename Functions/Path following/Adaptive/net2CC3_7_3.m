function [Y,Xf,Af] = net2CC3_7_3(X,~,~)
%NETTOT neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 24-Nov-2017 13:43:00.
% 
% [Y] = netTOT(X,~,~) takes these arguments:
% 
%   X = 1xTS cell, 1 inputs over TS timesteps
%   Each X{1,ts} = 2xQ matrix, input #1 at timestep ts.
% 
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = 1xQ matrix, output #1 at timestep ts.
% 
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1_xoffset = [0.1977;0.5];
x1_step1_gain = [0.60268193460901;0.102564102564103];
x1_step1_ymin = -1;

% Layer 1
b1 = [1.1268258907034729;1.7312722783516556;-1.5790988742439547];
IW1_1 = [-1.2239558891612594 0.016154759242180926;1.3409060814502869 0.00028096428788694706;1.2388619754734278 -2.4816268422212562];

% Layer 2
b2 = [-0.14274990156211415;1.7611251249783351;-0.76147899806578523;0.30126277401293539;-2.132001425468073;0.70990016812089651;-3.2078266187738422];
LW2_1 = [-3.3630247138336471 4.0624565085810582 -2.2341702723529315;2.015506469464182 -3.7827898152261996 -0.03729691530949393;-0.041927401859030336 -1.5355886662489797 -1.6782354743608996;0.73611651442610349 1.315079300001426 -0.41717272434290426;1.7501456845170247 -10.369529929967404 -12.973606670644719;-0.11489330823673681 1.8536078519382913 0.069773321173150812;-5.4510222976583007 -3.0674765911090374 7.5340421836218674];

% Layer 3
b3 = [0.92308058174409768;-0.25186815799007523;0.46327546999703356];
LW3_2 = [0.028241246506345016 -0.080184263513439144 0.029104056984126294 -1.793063487006735 0.010520418097280515 2.5063897644280577 1.7938916785439871;-3.9990221056617865 -0.031921543060815981 4.991541268331078 0.21193282874140745 0.70116168195764095 -1.2589093618235159 0.25186827924655614;0.42472681031060261 0.12350870060108013 2.5444556572761279 -0.83550532991930671 0.47701317020971207 1.8377247938939214 -1.1021777857598438];

% Layer 4
b4 = -3.7727294431480831;
LW4_3 = [10.628139580907842 -5.4341773375045577 -0.69232218180339433];

% Output 1
y1_step1_ymin = 0;
y1_step1_gain = 0.169491525423729;
y1_step1_xoffset = 0.25;

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX, X = {X}; end;

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
    Q = size(X{1},2); % samples/series
else
    Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS

    % Input 1
    Xp1 = mapminmax_apply(X{1,ts},x1_step1_gain,x1_step1_xoffset,x1_step1_ymin);
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1);
    
    % Layer 2
    a2 = tansig_apply(repmat(b2,1,Q) + LW2_1*a1);
    
    % Layer 3
    a3 = tansig_apply(repmat(b3,1,Q) + LW3_2*a2);
    
    % Layer 4
    a4 = logsig_apply(repmat(b4,1,Q) + LW4_3*a3);
    
    % Output 1
    Y{1,ts} = mapminmax_reverse(a4,y1_step1_gain,y1_step1_xoffset,y1_step1_ymin);
end

% Final Delay States
Xf = cell(1,0);
Af = cell(4,0);

% Format Output Arguments
if ~isCellX, Y = cell2mat(Y); end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings_gain,settings_xoffset,settings_ymin)
y = bsxfun(@minus,x,settings_xoffset);
y = bsxfun(@times,y,settings_gain);
y = bsxfun(@plus,y,settings_ymin);
end

% Sigmoid Positive Transfer Function
function a = logsig_apply(n)
a = 1 ./ (1 + exp(-n));
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n)
a = 2 ./ (1 + exp(-2*n)) - 1;
end

% Map Minimum and Maximum Output Reverse-Processing Function
function x = mapminmax_reverse(y,settings_gain,settings_xoffset,settings_ymin)
x = bsxfun(@minus,y,settings_ymin);
x = bsxfun(@rdivide,x,settings_gain);
x = bsxfun(@plus,x,settings_xoffset);
end
